\documentclass[11pt]{article}
% Packages used by instructor %
\usepackage{amsmath,amssymb,xspace,epsfig}
\newcommand{\sectionbreak}{\clearpage}

% Package for new section on new page
\usepackage{titlesec}

%Package used for formatting lists%
\usepackage[shortlabels]{enumitem}

% Package used for setting up page margins %
\usepackage{geometry}
%\usepackage{showframe} % Used to clearly show the new margins %
\newgeometry{vmargin={1in}, hmargin={1in,1in}}

% Package used for adding hyperlinks %
\usepackage{hyperref}

% Package for multirow tables %
\usepackage{multirow}
\renewcommand{\arraystretch}{1.5}

% Package for displaying algorithms %
\usepackage{algorithm}
\usepackage{algpseudocode}

% Page Header %
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Ananlysis of Algorithms \\ Home Work 1}
\rhead{Narayan Acharya \\ 112734365}
\lfoot{\leftmark}
\rfoot{\thepage}

\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}

\title{
	Analysis of Algorithms - Home Work 1\\[2mm]
	\large CSE 548 Fall '19\\[1mm]
	\href{mailto:jgao@cs.stonybrook.edu}{\textit{Prof. Jie Gao}}
}
\author{
	\small Submission By: \\
	\href{mailto:nacharya@cs.stonybrook.edu}{Narayan Acharya} \\
	\small 112734365
}
\date{\vspace{-5ex}}
\begin{document}

% Set up title
\maketitle
\thispagestyle{fancy} % Make this page use fancy header

\section{Question 1}

\textbf{Big-O notation (10pts)} Prove or disprove (i.e., give counter examples) for the following claims. $f(n), g(n)$ are non-negative functions.
    \begin{enumerate}
    \item $\max(f(n), g(n))=\Theta(f(n)+g(n))$. \\
    \textbf{Solution:}
    Given $f(n)$ and $g(n)$ are non-negative functions we know that:
    \begin{equation*}
    \begin{split}
	    f(n) \le f(n) + g(n) \\
	    g(n) \le f(n) + g(n) \\
	\end{split}
    \end{equation*}
    Either function is less than the sum of the two functions.
    \begin{equation*} 
    \therefore max(f(n), g(n)) \le f(n) + g(n) \\
    \end{equation*}
    \begin{equation} \label{eq:1a1}
        \boxed{max(f(n), g(n)) = O(f(n)+g(n))}
    \end{equation}
    
    Also,
    \begin{equation*}
		max(f(n), g(n)) >= \frac{(f(n)+g(n))}{2}
    \end{equation*}
    \begin{equation} \label{eq:1a2}
	    \boxed{max(f(n), g(n)) = \Omega(f(n)+g(n))}
    \end{equation}
    
    From results \ref{eq:1a1} and \ref{eq:1a2},
    \begin{equation*}
	    \boxed{max(f(n), g(n)) = \Theta(f(n)+g(n))}
    \end{equation*}
    
    \item $o(f(n)) \cap \omega(f(n))=\emptyset$. \\
    \textbf{Solution:} $o(f(n))$, by definition, is a function that \textit{grows strictly slower} than $(f(n))$ while $\omega(f(n))$, by definition, is a function that \textit{grows strictly faster} than $f(n)$.
    \begin{equation} \label{eq:1b1}
    	o(f(n)) < f(n) : \forall n
    \end{equation} 
    \begin{equation} \label{eq:1b2}
	    \omega(f(n)) > f(n) : \forall n
    \end{equation}
	Equations \ref{eq:1b1} and \ref{eq:1b2} imply that these functions are on the opposite sides of the tightest possible growth rate function and can never be same or overlap. Therefore, the intersection of these functions is rightly an empty set, $\emptyset$ and the statement \textbf{$o(f(n)) \cap \omega(f(n))=\emptyset$ is true}.
    
    \item $(n+a)^b=\Theta(n^b)$, $a, b$ are positive integers. \\
    \textbf{Solution:} $(n+a)^b$ is a polynomial of order b. The expression expanded using Binomial Theorem with all its terms will look like this:
	\begin{equation} \label{eq:1c1}
		  (n+a)^b = {b \choose 0}.n^{b}.a^0 + {b \choose 1}.n^{(b-1)}.a^1 + \ldots + {b \choose b}.n^{0}.a^b
	\end{equation}
	But we know that for terms where order of n is $ \le b$,
	\begin{equation} \label{eq:1c2}
	  {b \choose 1}.n^{(b-1)}.a^1 \leq n \times {b \choose 1}.n^{(b-1)}.a^1 : \forall n \geq 1
	\end{equation}
	\begin{equation} \label{eq:1c3}
		{b \choose 1}.n^{(b-2)}.a^1 \leq n^{2} \times {b \choose 1}.n^{(b-2)}.a^2 : \forall n \geq 1 \ldots
	\end{equation}
		
	Therefore from equations \ref{eq:1c1}, \ref{eq:1c2} and \ref{eq:1c3}we can deduce that, $\forall n \geq 1$, \\
	\begin{equation*}
		{b \choose 0}.n^{b}.a^0 + {b \choose 1}.n^{(b-1)}.a^1 + \ldots + {b \choose b}.n^{0}.a^b \le {b \choose 0}.n^{b}.a^0 +  n \times {b \choose 1}.n^{(b-1)}.a^1 + n^{2} \times {b \choose 1}.n^{(b-2)}.a^{2} \ldots
	\end{equation*}
	\begin{equation*}
	\begin{split}
		(n+a)^b & \le n^{b} \times {b \choose 1}.a^1 + {b \choose 1}.a^{2} \ldots {b \choose b}.a^{b} \\
		& \le c \times n^{b}
	\end{split}
	\end{equation*}
	where $c = {b \choose 1}.a^1 + {b \choose 1}.a^{2} \ldots {b \choose b}.a^{b}$
	
	\begin{equation} \label{eq:1c4}
		\boxed{\therefore (n+a)^b = O(n^{b})}
	\end{equation}
	
	On similar lines, we can also prove $(n+a)^b=\Omega(n^b)$ using the fact that all terms other than that of order b for n contribute positively in equation \ref{eq:1c1},
	\begin{equation*}
		(n+a)^b \ge {b \choose 0}.a^0.n^{b}
	\end{equation*}
	\begin{equation} \label{eq:1c5}
		\boxed{\therefore (n+a)^b=\Omega(n^b)}
	\end{equation}
	
	From equations \ref{eq:1c4} and \ref{eq:1c5},
	\begin{equation*}
		\boxed{(n+a)^b=\Theta(n^b)}
	\end{equation*}
	
    \item $f(n)=O(f(n)^2)$. \\
    \textbf{Solution:}
   	Given that $f(n)$ is a non-negative function,
    \begin{equation*}
		f(n) \le  c \times f(n) : \forall n \ge n_0, c > 0
    \end{equation*}
    \begin{equation*}
		\therefore f(n)^2 \le  c^2 \times f(n)^2
	\end{equation*}
	\begin{equation*}
		\boxed{\therefore f(n)^2 =  O(f(n)^2)}
	\end{equation*}
	$f(n)^2$ may or may not be the tightest bound for $f(n)$ but it is asymptotically upper bound for a non-negative function $f(n)$.
	
    \item $f(n)=O(g(n))$ implies that $2^{f(n)}=O(2^{g(n)})$. \\
    \textbf{Solution:}
    Say $f(n)=k \times n$, given we have $f(n)=O(g(n))$, $g(n)=n$. \\
	\begin{equation*}
    \therefore 2^{f(n)} = 2^{(k \times n)}, 2^{g(n)} = 2^n
    \end{equation*}
    \begin{equation*}
    \therefore O(2^{f(n)}) = O(2^{(k \times n)})
    \end{equation*}
    But, $O(2^{g(n)}) = O(2^{n}) \ne O(2^{(k \times n))} :  \forall k \neq 1$
	\begin{equation*}
	    \boxed{\therefore 2^{f(n)} \ne O(2^{g(n)})}
	\end{equation*}

    \end{enumerate}
    

\section{Question 2}

Sort the following functions from asymptotically smallest to asymptotically largest. That is, the function $f(n)$ and the next function $g(n)$ must always follow that $f(n) \in O(g(n))$. If the two functions have asymptotic the same order, i.e., $f(n)=\Theta(g(n))$, then also indicate that. No need to write down proofs.  Remember $\lg n=\log_2 n$.
  
$n$, $\lg n$, $\sqrt{n}$, $\sqrt{\lg n}$, $\lg \sqrt{n}$, $2^n$, $2^{\sqrt{n}}$, $\sqrt{2^n}$, $2^{\lg n}$, $\lg(2^n)$, $2^{\lg \sqrt{n}}$, $2^{\sqrt{\lg n}}$, $\sqrt{2^{\lg n}}$, $\lg (\sqrt{2^n})$, $\sqrt{\lg (2^n)}$,  $3^n$, $3^{\sqrt{n}}$, $\sqrt{3^n}$, $3^{\lg n}$, $\lg(3^n)$, $3^{\lg \sqrt{n}}$, $3^{\sqrt{\lg n}}$, $\sqrt{3^{\lg n}}$, $\lg (\sqrt{3^n})$, $\sqrt{\lg (3^n)}$. \\

\textbf{Solution:} Below is table of the above functions sorted from asymptotically smallest to largest. \textit{Note:} Even though Row 14 onwards all functions are exponential in nature they are asymptotically different and therefore have different values of $g(n)=O(f(n))$.

\newcounter{rownumbers}
\newcommand\rownumber{\stepcounter{rownumbers}\arabic{rownumbers}}

\begin{center}
	\begin{tabular}{ |c|c|c|c| } 
		\hline
		Row & Function & Simplified Representation & $g(n)=O(f(n))$\\
		\hline
		\rownumber & $\sqrt{\lg n}$ & $\sqrt{\lg n}$ & $\sqrt{\lg n}$ \\
		\hline
		\rownumber & $\lg \sqrt{n}$ & $\lg (n)/2$ & \multirow{2}{4em}{$\lg {n}, \Theta(\lg {n})$}\\ \cline{1-3}
		\rownumber & $\lg n$ & $\lg n$ & \\
		\hline
		\rownumber & $2^{\sqrt{\lg n}}$ & $2^{\sqrt{\lg n}}$ & $2^{\sqrt{\lg n}}$ \\
		\hline
		\rownumber & $3^{\sqrt{\lg n}}$ & $3^{\sqrt{\lg n}}$ & $3^{\sqrt{\lg n}}$ \\
		\hline
		\rownumber & $\sqrt{n}$ , $\sqrt{2^{\lg n}}$ , $2^{\lg \sqrt{n}}$ & $\sqrt{n}$ & \multirow{3}{4em}{$\sqrt{n}, \Theta(\sqrt{n})$}\\ \cline{1-3}
		\rownumber & $\sqrt{\lg (2^n)}$ & $\sqrt{\lg (2)} \times \sqrt{n}$ & \\ \cline{1-3}
		\rownumber & $\sqrt{\lg (3^n)}$ & $\sqrt{\lg (3)} \times \sqrt{n}$ & \\ \cline{1-3}
		\hline
		\rownumber & $3^{\lg \sqrt{n}}$ , $\sqrt{3^{\lg n}}$ & $n^{\lg \sqrt{3}}$ & $n^{\lg \sqrt{3}}$ \\
		\hline
		\rownumber & $\lg (\sqrt{2^n})$ & $n \times \lg (2)/2$ & \multirow{4}{4em}{$n, \Theta(n)$}\\ \cline{1-3}
		\rownumber & $\lg (\sqrt{3^n})$ & $n \times \lg (3)/2$ & \\ \cline{1-3}
		\rownumber & $n$ , $\lg(2^n)$ , $2^{\lg n}$ & $n$ & \\ \cline{1-3}
		\rownumber & $\lg(3^n)$ & $n \times lg (3)$ & \\ \cline{1-3}
		\hline
		\rownumber & $3^{\lg n}$ & $n^{\lg 3}$ & $n^{\lg 3}$ \\
		\hline
		\rownumber & $2^{\sqrt{n}}$ & $2^{\sqrt{n}}$ & $2^{\sqrt{n}}$ \\
		\hline
		\rownumber & $3^{\sqrt{n}}$ & $3^{\sqrt{n}}$ & $3^{\sqrt{n}}$ \\
		\hline
		\rownumber & $\sqrt{2^n}$ & $\sqrt{2^n}$ & $\sqrt{2^n}$ \\
		\hline
		\rownumber & $\sqrt{3^n}$ & $\sqrt{2^n}$ & $\sqrt{2^n}$ \\
		\hline
		\rownumber & $2^n$ & $2^n$ & $2^n$ \\
		\hline
		\rownumber & $3^n$ & $3^n$ & $3^n$ \\
		\hline
		
	\end{tabular}
\end{center}


\section{Question 3} Textbook [Kleinberg \& Tardos] Chapter 2, page 67, problem \#6. \\

\textbf{Solution:}

\begin{enumerate}[(a)]
	\item The algorithm given in the question has an upper bound of the order $n^3$. This can be proved as follows:
	
	The algorithm loops over i n-times. During each iteration over i it loops over j (n-i)-times. For adding all the elements from A[i] through A[j], there needs to be an additional loop, say with index k,  (j-i+1)-times.
	
	The above can be represented as a function of n as:
	\begin{equation*}
		f(n) = \sum_{i=1}^{i=n} {\sum_{j=i+1}^{j=n} \sum_{k=i}^{k=j} {Add!}}
	\end{equation*}
	Expanding and simplifying the series: \\ \textit{Note: The 'Add!' operation is considered constant time and hence omitted from the series below as it contributes only a factor of 1 to each term.}
	\begin{equation*}
	\begin{split}
		f(n) & = (n-1).(1) + (n-2).(2) + (n-3).(3) + \ldots + (n-n).(n) \\
		& = [(n + 2n + 3n + \ldots + n.n) - (1 + 4 + 9 + \ldots + n^2)]
	\end{split}
	\end{equation*}
	Simplifying this equation we get (Using formulas for adding a series n natural numbers and their squares):
	\begin{equation*}
		f(n) = \frac{(n^3 - n)}{6}
	\end{equation*}
	The function is a polynomial of the order 3.
	\begin{equation*}
		\boxed{\therefore f(n) = O(n^3)}
	\end{equation*}
	
	\item To show that $\Omega(f(n)) = n^3 $ we need $\exists c > 0$ for $n \ge n_0$ satisfying $f(n) \ge c \times n^3$. We will find a valid $c$ assuming that the condition holds.
	\begin{equation*}
	\begin{split}
		\therefore \frac{(n^3 - n)}{6} \ge c \times n^3 \\
		\therefore \frac{(n^3 - n)}{6 \times n^3} \ge c \\
		\therefore c \le \frac{(n^2 - 1)}{6 \times n^2} \\
	\end{split}
	\end{equation*}
	A valid $c$ exists for all $n > 1$.
	\begin{equation*}
		\boxed{\therefore f(n) = \Omega(n^3)}
	\end{equation*}
	
	\item The given algorithm is inefficient as the innermost loop is not needed. Instead of iterating over all elements A[i] through A[j] while adding them, we can keep track of the sum after each iteration over i and use that as our seed for adding as we loop over j as shown. \\
	\begin{algorithm}
		\caption{Improved algorithm with $ O(n^2) $}
		\begin{algorithmic}[1]
			\For{$ i \gets 1, 2, 3 \ldots n $}
				\State $ sumSoFar \gets A[i] $
				\For{$ j \gets i+1, i+2, i+3 \ldots n $}
					\State $ sumSoFar \gets sumSoFar + A[j] $
					\State $ B[i][j] \gets sumSoFar $
				\EndFor
			\EndFor
		\end{algorithmic}
	\end{algorithm}
	The running time of this algorithm can be represented as a function of n as:
	\begin{equation*}
		g(n) = \sum_{i=1}^{i=n} {\sum_{j=i+1}^{j=n} {Add!}}
	\end{equation*}
	Expanding the series:
	\begin{equation*}
	\begin{split}
		g(n) & = (n-1) + (n-2) + (n-3) + \ldots + (n-n) \\
		& = (n + n + n + \ldots + n) - (1 + 2 + 3 + \ldots + n)
	\end{split}
	\end{equation*}
	Simplifying this equation we get:
	\begin{equation*}
		g(n) = \frac{(n^2 - n)}{2}
	\end{equation*}
	To prove that this algorithm is asymptotically better, we need to prove $lim_{n\to\infty} \frac{g(n)}{f(n)} = 0$.
	\begin{equation*}
	\begin{split}
		lim_{n\to\infty} \frac{g(n)}{f(n)} & = lim_{n\to\infty} {\frac{\frac{(n^2 - n)}{2}}{\frac{(n^3 - n)}{6}}} \\
		& = lim_{n\to\infty} {\frac{(n - 1) \times 3}{n^2 - 1}} \\
		& = lim_{n\to\infty} {\frac{(n - 1) \times 3}{(n - 1) \times (n + 1)}} \\
		& = lim_{n\to\infty} {\frac{3}{n + 1}} \\
		& = 0
	\end{split}
	\end{equation*}
	\begin{equation*}
		\therefore lim_{n\to\infty} \frac{g(n)}{f(n)} = 0
	\end{equation*}

	Hence, proposed algorithm's running time is asymptotically better.
\end{enumerate}

\section{Question 4} Recall that in a heap we keep the elements such that the parent is smaller than children. Thus the root (stored as the first element in the array) is the smallest item in the array. Insertion and of a new element can be done in $O(\lg n)$ time. Deletion of an element can be done in $O(\lg n)$ time. Thus one start from an empty heap and insert elements one by one to build a heap of $n$ elements. Further, we can use it to sort $n$ elements. Once the heap is built, we remove the root (the smallest element), which is the smallest of the $n$ elements. Iterate and we will get all $n$ elements output in the increasing sorted order.  This algorithm is called  \textsc{HeapSort}.
 
\begin{enumerate}
\item What is the running time for \textsc{HeapSort}? Assume elements come in an arbitrary order and represent the running time in big-O notation. (2pts) \\
\textbf{Solution:} 

In order to construct a heap with stable heap-order property for $ n $ elements when they arrive in \textbf{arbitrary} order, we need $O(\log(n))$ operation for each new element that we insert i.e we need $O(n\log(n))$ time to construct the heap.

To sort the elements we need to extract the root element and then \textit{heapify} the heap to enforce heap-order property again for $ n $ elements. The operation will take $O(\log(n))$ for each of the $ n $ elements. Thus, to sort the $ n $ elements we need $O(n\log(n))$ time.

Thus, we need $ O(n\log(n)) $ to construct ($ O(n\log(n)) $) the heap and sort ($ O(n\log(n)) $) it when the elements arrive in arbitrary order. \\

\item What is the running time of \textsc{HeapSort} on $n$ elements in increasing order? Represent the running time in big-$\Theta$ notation. (4pts) \\
\textbf{Solution:} 

In order to construct a heap with stable heap-order property for $ n $ elements when they arrive in \textbf{ascending} order, we need $O(1)$ operation for each new element as they simply will be added to the end of the heap and heap-order property will be intact. Thus, we need $O(n)$ time to construct the heap.

To sort the elements we need to extract the root element and then \textit{heapify} the heap to enforce heap-order property again for $ n $ elements. The operation will take $O(\log(n))$ for each of the $ n $ elements. Thus, to sort the $ n $ elements we need $O(n\log(n))$ time.

Thus, we need $ O(n\log(n)) $ to construct ($O(n)$) the heap and sort ($O(n\log(n))$) it when the elements arrive in arbitrary order. \\

\item What is the running time of \textsc{HeapSort} on $n$ elements in decreasing order?  Represent the running time in big-$\Theta$ notation. (4pts) \\
\textbf{Solution:} 

The case when numbers are in \textbf{descending} order is the same as they arrive in arbitrary order, asymptotically speaking. We will need similar operations to construct the heap and extract the elements for sorting.

Thus, we need $ O(n\log(n)) $ to construct ($ O(n\log(n)) $) the heap and sort ($ O(n\log(n)) $) it when the elements arrive in descending order. \\
\end{enumerate}

\section{Question 5} \textbf{Young Tableaus} An $m \times n$ Young tableau is an $m\times n$ matrix such that the entries of each row are in increasing order from left to right and the entries of each column are in increasing order from top to bottom. Some of the entries of each column may be $\infty$, which are treated as nonexistent elements. A Young tableau with some elements as $\infty$ is not full. 

Give an algorithm that extracts MIN (i.e., delete the minimum element and restore the matrix to be a Young tableau) on a nonempty $m\times n$ Young tableau that runs in $O(m+n)$ time. \\

\textbf{Solution:} Consider the following algorithm to extract minimum from Young Tableau and then restores the Young Tableau property. \\

\begin{algorithm}
	\caption{Algorithm to extract minimum from Young Tableau with $ m $ rows and $ n $ columns $ O(m+n) $}
	\begin{algorithmic}[1]
		\Procedure{ExtractMin}{$YT$}\Comment{Extracts minimum from Young Tableau $YT$}
			\State $ extractedMin = YT[0][0] $
			\State $ m \gets len(YT) $ \Comment{$ m $ rows of $ YT $}
			\State $ n \gets len(YT[0]) $ \Comment{$ n $ columns of $ YT $}
			\State $ YT[0][0] = YT[m-1][n-1] $ \Comment{Moves largest element to $ YT[0][0] $}
			\State $ MakeYT(YT, 0, 0) $
		\EndProcedure
		
		\Procedure{MakeYT}{$T$, $ i $, $ j $}\Comment{Restores Young Tableau property of matrix $ T $}
			\State $ m \gets len(YT) $ \Comment{$ m $ rows of $ YT $}
			\State $ n \gets len(YT[0]) $ \Comment{$ n $ columns of $ YT $}
			\If {$i < m$ and $j < n$}
				\State $ nextRow \gets T[i+1][j] $ if $ i+1 \neq m $ else $ None $
				\State $ nextCol \gets T[i][j+1] $ if $ j+1 \neq n $ else $ None $
				
				\If{$ nextRow = None $ and $ nextCol == None $}
					\State \Return \Comment{No number to the right or below to compare. Done!}
				\EndIf
				
			\EndIf
			\State $ extractedMin = YT[0][0] $
			\State $ m \gets len(YT) $ \Comment{$ m $ rows of $ YT $}
			\State $ n \gets len(YT[0]) $ \Comment{$ n $ columns of $ YT $}
			\State $ YT[0][0] = YT[m-1][n-1] $ \Comment{Moves largest element to $ YT[0][0] $}
			\State $ MakeYT(YT, 0, 0) $
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\end{document}